# -*- coding: utf-8 -*-
"""bot_ajedrez_tesis_chatgpt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rjmw78HJBnlWrfxYnyH7s-9na3eE_-32
"""

!pip install chess

#importar librerías
import numpy as np
import random
import chess
import chess.svg
from IPython.display import SVG

#definir la clase del bot de ajedrez
class ChessBot:

    #definir los atributos del bot
    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1):
        self.alpha = alpha
        self.gamma = gamma
        self.epsilon = epsilon
        self.board = chess.Board()
        self.q_table = {}

    #definir el método para seleccionar la mejor jugada
    def select_best_move(self):
        best_move = None
        best_value = -9999

        #recorrer todas las jugadas posibles
        for move in self.board.legal_moves:
            #obtener el valor de la jugada
            value = self.q_table.get((self.board.fen(), move), 0)

            #actualizar el mejor valor y la mejor jugada
            if value > best_value:
                best_value = value
                best_move = move

        return best_move

    #definir el método para seleccionar una jugada aleatoria
    def select_random_move(self):
        #obtener todas las jugadas posibles
        moves = list(self.board.legal_moves)

        #seleccionar una jugada aleatoria
        return random.choice(moves)

    #definir el método para seleccionar una jugada
    def select_move(self):
        #si el número aleatorio es menor que epsilon, seleccionar una jugada aleatoria
        if random.random() < self.epsilon:
            return self.select_random_move()

        #de lo contrario, seleccionar la mejor jugada
        else:
            return self.select_best_move()

    #definir el método para actualizar la tabla Q
    def update_q_table(self, old_state, action, reward, new_state):
        #obtener el valor de la jugada anterior
        old_value = self.q_table.get((old_state, action), 0)

        #obtener el valor de la mejor jugada en el nuevo estado
        
        if(not self.board.is_game_over()):
            best_new_value = max([self.q_table.get((new_state, a), 0) for a in self.board.legal_moves])
            new_value = (1 - self.alpha) * old_value + self.alpha * (reward + self.gamma * best_new_value)
            print("1 - ", new_value, best_new_value)
        else:
            new_value = (1 - self.alpha) * old_value + self.alpha * reward
            print("2 - ", new_value)
        self.q_table[(old_state, action)] = new_value


    def play_against_bot(self):
        done = False
        self.board.reset()
        while not done:

            action = self.select_move()
            #realizar la jugada
            self.board.push(action)
            print(self.board)
            #obtener el nuevo estado
            new_state = self.board.fen()

            move = input("Ingrese su movimiento: ")
            self.board.push_san(move)
            print(self.board)
               
    #definir el método para jugar una partida
    def play(self, num_episodes=1000):
        #recorrer todas las partidas
        for episode in range(num_episodes):
            #reiniciar el tablero
            self.board.reset()

            #recorrer todos los movimientos
            while not self.board.is_game_over():
                #obtener el estado actual
                old_state = self.board.fen()

                #seleccionar una jugada
                action = self.select_move()

                #realizar la jugada
                self.board.push(action)

                #obtener el nuevo estado
                new_state = self.board.fen()       

                #actualizar la tabla Q
            if(self.board.result() == '1/2-1/2' or self.board.result()=='*'):
                reward = 0
            if(self.board.result() == '1-0'):
                reward = 1
            if(self.board.result() == '0-1'):
                reward = -1
            
            self.update_q_table(old_state, action, reward, new_state)
                

            #imprimir el resultado de la partida
            #print(f'Partida {episode}: {self.board.result()}')

#crear una instancia del bot de ajedrez
bot = ChessBot()

#jugar 1000 partidas
bot.play(500)
print("end-entrenamiento")

bot.play_against_bot()

#importar librerías
import numpy as np
import random
import chess
import chess.svg
from IPython.display import SVG

#definir la clase del bot de ajedrez
class ChessBot:

    #definir los atributos del bot
    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1):
        self.alpha = alpha
        self.gamma = gamma
        self.epsilon = epsilon
        self.board = chess.Board()
        self.q_table = {}

    #definir el método para seleccionar la mejor jugada
    def select_best_move(self):
        best_move = None
        best_value = -float('inf')

        #recorrer todas las jugadas posibles
        for move in self.board.legal_moves:
            #obtener el valor de la jugada
            value = self.q_table.get((self.board.fen(), move), 0)

            #actualizar el mejor valor y la mejor jugada
            if value > best_value:
                best_value = value
                best_move = move

        return best_move

    #definir el método para seleccionar una jugada aleatoria
    def select_random_move(self):
        #obtener todas las jugadas posibles
        moves = list(self.board.legal_moves)

        #seleccionar una jugada aleatoria
        return random.choice(moves)

    #definir el método para seleccionar una jugada
    def select_move(self):
        #si el número aleatorio es menor que epsilon, seleccionar una jugada aleatoria
        if random.random() < self.epsilon:
            return self.select_random_move()

        #de lo contrario, seleccionar la mejor jugada
        else:
            return self.select_best_move()

    #definir el método para actualizar la tabla Q
    def update_q_table(self, old_state, action, reward, new_state):
        #obtener el valor de la jugada anterior
        old_value = self.q_table.get((old_state, action), 0)

        #obtener el valor de la mejor jugada en el nuevo estado
        best_new_value = max([self.q_table.get((new_state, a), 0) for a in self.board.legal_moves])

        #actualizar el valor de la jugada
        new_value = (1 - self.alpha) * old_value + self.alpha * (reward + self.gamma * best_new_value)

        #actualizar la tabla Q
        self.q_table[(old_state, action)] = new_value

    #definir el método para jugar una partida
    def play(self, num_episodes=1000):
        #recorrer todas las partidas
        for episode in range(num_episodes):
            #reiniciar el tablero
            self.board.reset()

            #recorrer todos los movimientos
            while not self.board.is_game_over():
                #obtener el estado actual
                old_state = self.board.fen()

                #seleccionar una jugada
                action = self.select_move()

                #realizar la jugada
                self.board.push(action)

                #obtener el nuevo estado
                new_state = self.board.fen()

                #calcular la recompensa
                reward = self.board.result()

                #actualizar la tabla Q
                self.update_q_table(old_state, action, reward, new_state)

            #imprimir el resultado de la partida
            print(f'Partida {episode}: {self.board.result()}')

#crear una instancia del bot de ajedrez
bot = ChessBot()

#jugar 1000 partidas
bot.play(1000)